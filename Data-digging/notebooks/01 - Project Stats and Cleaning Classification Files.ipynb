{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computing Project Stats and Cleaning Up Classification Exports\n",
    "\n",
    "When project teams first download classification exports, they usually need to do the following:\n",
    " - Calculate some statistics for classifications, classifiers, and the project in general\n",
    " - Extract just the classifications they want from the raw export (e.g. remove duplicates, classifications of old workflows, and test classifications from before the project was live)\n",
    "This notebook will show you how to do both of these things using Python scripts that exist in this repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version: 3.6.3, numpy version: 1.15.3, pandas version: 0.20.3.\n",
      "Originally developed using Py 2.7.11, np v1.11.0, pd v0.19.2\n",
      "If these versions don't match and stuff breaks, that's probably why.\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "print(\"Python version: %d.%d.%d, numpy version: %s, pandas version: %s.\" %(sys.version_info[0], \n",
    "                                                                           sys.version_info[1], \n",
    "                                                                           sys.version_info[2], \n",
    "                                                                           np.__version__, \n",
    "                                                                           pd.__version__))\n",
    "print(\"Originally developed using Py 2.7.11, np v1.11.0, pd v0.19.2\")\n",
    "print(\"If these versions don't match and stuff breaks, that's probably why.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most common project statistics are computed as part of `basic_classification_processing`, which used to be `basic_project_stats` (but was renamed because it does more than that)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from basic_classification_processing import basic_stats_processing, basic_stats_help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing project stats using:\n",
      "   infile: western-montana-wildlife-classifications.csv\n",
      "Reading classifications from western-montana-wildlife-classifications.csv\n",
      "Considering all classifications in workflow ids:\n",
      "[3101 3140]\n",
      " and workflow_versions:\n",
      "[ 22.38   83.125  85.141 103.132 105.133 136.134 140.135 212.136 213.136\n",
      " 214.137 219.143 220.144 221.144 222.144 223.145 224.145 225.146]\n",
      "Retaining all non-live classifications in analysis.\n",
      "\n",
      "Overall:\n",
      "\n",
      "492111 classifications of 62470 subjects by 7228 classifiers,\n",
      "4503 logged in and 2725 not logged in, from 9146 unique IP addresses.\n",
      "438644 classifications were from logged-in users, 53467 from not-logged-in users.\n",
      "\n",
      "That's 7.88 classifications per subject on average (median = 5.0).\n",
      "The most classified subject has 42 classifications; the least-classified subject has 1.\n",
      "\n",
      "Median number of classifications per user: 13.00\n",
      "Mean number of classifications per user: 68.08\n",
      "\n",
      "Top 10 most prolific classifiers:\n",
      "user_name\n",
      "Annhedderick                          12120\n",
      "krosestone                             6988\n",
      "FridrunFW                              6641\n",
      "Mikusan                                4531\n",
      "Drafthorse1                            3661\n",
      "DAE48                                  3626\n",
      "Kjreynolds1957                         3565\n",
      "not-logged-in-9452f075193036193d93     3527\n",
      "Doobydoo28                             3321\n",
      "Dragoncubes                            3263\n",
      "Name: user_name, dtype: int64\n",
      "\n",
      "\n",
      "Gini coefficient for classifications by user: 0.81\n",
      "\n",
      "Classifications were collected between 2016-12-09 and 2018-10-26.\n",
      "The highest classification id considered here is 128757714.\n",
      "\n",
      "File with ranked list of user classification counts written to western-montana-wildlife-classifications_nclass_byuser_ranked.csv .\n"
     ]
    }
   ],
   "source": [
    "project_name = \"western-montana-wildlife\"\n",
    "\n",
    "classification_file = project_name + \"-classifications.csv\"\n",
    "\n",
    "# if you want to do this separately you need to also import read_classfile from \n",
    "# basic_classification_processing above\n",
    "#classifications = read_classfile(classification_file)\n",
    "\n",
    "# compute the most basic stats, not worrying about duplicate or non-live classifications \n",
    "# or multiple workflows\n",
    "basic_stats_processing(classification_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making sense of the stats output\n",
    "\n",
    "There's a lot of information here. Let's break it down.\n",
    "\n",
    " 1. **Workflow information**\n",
    " -- The first thing the program prints is a list of all workflow IDs with at least one classification in the file, followed by the versions of those workflows (note, it doesn't match them up). This tells you what this export covers. The example \"My Project\" file has 3 workflows, with one version of each, but this can vary by project. \n",
    " \n",
    " 2. **Classification and Classifier counts, averages, medians**\n",
    " -- This is meant to give you a sense of who is classifying and how many classifications they're doing. The IP address count is meant to help you estimate how many of the not-logged-in classifiers are people who went to the project, started classifying, and logged in later (their not-logged-in classifications will have the same IP address and browser session). The difference between means and medians gives you a sense of how skewed the distributions of classifications (per classifier and per subject) are.\n",
    " \n",
    " 3. **Top 10 most prolific classifiers**\n",
    " -- Leaderboards can be useful just to see who's doing what in your project, but *we do not recommend sharing them publicly* because they tend to encourage people to prioritize getting on the leaderboard, sometimes by sacrificing accuracy in favor of classifying fast. Plus, it may not be a great idea to imply that the people who classify the most are also the most valuable volunteers. However, this can be useful internally so you know who your most prolific classifiers are (they aren't always the people who post the most on Talk).\n",
    " \n",
    " 4. **Gini coefficient**\n",
    " -- The Gini coefficient measures inequality in distributions of things. It was originally conceived for economics (e.g. where is the wealth in a country? in the hands of many citizens or a few?), but it's just as applicable to many other fields. In this case we'll use it to see how classifications are distributed among classifiers.\n",
    " \n",
    " G = 0 is a completely even distribution (everyone does the same number of classifications), and ~1 is uneven (~all the classifications are done by one classifier). Typical values of the Gini for healthy Zooniverse projects (Cox et al. 2015) are in the range of 0.7-0.9. That range is generally indicative of a project with a loyal core group of  volunteers who contribute the bulk of the classification effort, but balanced out by a regular influx of new classifiers trying out the project, from which you continue to draw to maintain a core group of prolific classifiers. Once your project is fairly well established, you can compare it to past Zooniverse projects to see how you're doing.\n",
    " \n",
    " If your G is << 0.7, you may be having trouble recruiting classifiers into a loyal group of volunteers. People are trying it, but not many are staying. If your G is > 0.9, it's a little more complicated. If your total classification count is lower than you'd like it to be, you may be having trouble recruiting classifiers to the project, such that your classification counts are dominated by a few people. But if you have G > 0.9 and plenty of classifications, this may be a sign that your loyal users are -really- committed, so a very high G is not necessarily a bad thing.\n",
    "\n",
    " Of course the Gini coefficient is a simplified measure that doesn't always capture subtle nuances and so forth, but it's still a useful broad metric.\n",
    "\n",
    " 5. **Classification dates and highest classification ID**\n",
    " -- It's useful to make sure your classification dates cover the time period you think they should, and the classification ID may be useful if you need to request a data export for just the most recent classifications since a given classification ID.\n",
    " \n",
    " 6. **File with user classification counts**\n",
    " -- This is always saved when you run the stats file, mainly because it's generated necessarily as a result of computing these stats, and it can come in handy for other things.\n",
    " \n",
    "Note, however, that these are only what the function prints *by default*, and in the default a lot of options are turned off. \n",
    "\n",
    "Let's see the full set of options:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Usage: basic_stats_processing(classfile_in, workflow_id=-1, workflow_version=-1, time_elapsed=False, output_csv=False, remove_duplicates=False, keep_nonlive=True, keep_allcols=False, verbose=True)\n",
      "      classifications_infile is a Zooniverse (Panoptes) classifications data export CSV.\n",
      "\n",
      "  Optional inputs:\n",
      "    workflow_id=N\n",
      "       specify the program should only consider classifications from workflow id N\n",
      "    workflow_version=M\n",
      "       specify the program should only consider classifications from workflow version M\n",
      "       (note the program will only consider the major version, i.e. the integer part)\n",
      "    workflow_ver_min=Mmin, workflow_ver_max=Mmax\n",
      "       specify the program should consider classifications from workflow version >= Mmin\n",
      "       or <= Mmax, or Mmin <= workflow version <= Mmax, if both are specified\n",
      "       Note specifying either a min or max supersedes specifying a workflow_version.\n",
      "    outfile_csv=filename.csv\n",
      "       if you want the program to save a sub-file with only classification info from the workflow specified, give the filename here\n",
      "    --time_elapsed\n",
      "       specify the program should compute classification durations and total classification work effort\n",
      "    --remove_duplicates\n",
      "       remove duplicate classifications (subject-user pairs) before analysis.\n",
      "       memory-intensive for big files; probably best to pair with outfile_csv so you save the output.\n",
      "    --keep_nonlive\n",
      "       by default the program ignores classifications made while the project wasn't 'Live'; setting this will keep them in.\n",
      "    --keep_allcols\n",
      "       by default the program only keeps columns required for stats; use this with a specified outfile_csv to save all columns, including annotations. (If you're not using outfile_csv this will just waste memory.)\n",
      "    --silent\n",
      "       by default, the program is verbose and many of the outputs are to screen. Flag this if you just want to print outfiles and not have any screen output.\n",
      "\n",
      "Verbose output will be to stdout (about 1-2 paragraphs' worth).\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print help for basic_stats_processing()\n",
    "\n",
    "basic_stats_help()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring the different options\n",
    "\n",
    "Let's say we want to run the stats function but only consider classifications from a specific workflow (say, `workflow_id = 5030`) *and* remove duplicate classifications *and* estimate the total amount of human effort the classifiers contributed during those classifications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow_id = 3101"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing project stats using:\n",
      "   infile: western-montana-wildlife-classifications.csv\n",
      "Reading classifications from western-montana-wildlife-classifications.csv\n",
      "Considering only workflow id 3101\n",
      "Considering all classifications in workflow_versions:\n",
      "[ 22.38   83.125 103.132 105.133 136.134 140.135 212.136 213.136 214.137\n",
      " 219.143 220.144 221.144 222.144 223.145 224.145 225.146]\n",
      "Retaining all non-live classifications in analysis.\n",
      "Found 1350 duplicate classifications (0.27 percent of total).\n",
      "Duplicates removed from analysis (1239 unique user-subject-workflow groups).\n",
      "\n",
      "Overall:\n",
      "\n",
      "490760 classifications of 62469 subjects by 7228 classifiers,\n",
      "4503 logged in and 2725 not logged in, from 9142 unique IP addresses.\n",
      "438136 classifications were from logged-in users, 52624 from not-logged-in users.\n",
      "\n",
      "That's 7.86 classifications per subject on average (median = 5.0).\n",
      "The most classified subject has 39 classifications; the least-classified subject has 1.\n",
      "\n",
      "Median number of classifications per user: 13.00\n",
      "Mean number of classifications per user: 67.90\n",
      "\n",
      "Top 10 most prolific classifiers:\n",
      "user_name\n",
      "Annhedderick      12112\n",
      "krosestone         6951\n",
      "FridrunFW          6641\n",
      "Mikusan            4526\n",
      "Drafthorse1        3661\n",
      "DAE48              3625\n",
      "Kjreynolds1957     3543\n",
      "Doobydoo28         3320\n",
      "Dragoncubes        3263\n",
      "steepleKen         3223\n",
      "Name: user_name, dtype: int64\n",
      "\n",
      "\n",
      "Gini coefficient for classifications by user: 0.81\n",
      "\n",
      "Classifications were collected between 2016-12-09 and 2018-10-26.\n",
      "The highest classification id considered here is 128757714.\n",
      "\n",
      "Based on 488522 classifications (99.5 percent) where we can probably\n",
      "trust the classification durations, the classifiers spent a total of 206.47 days\n",
      "(or 0.57 years) classifying in the project.\n",
      "\n",
      "Mean classification length:     36.5 seconds\n",
      "Median classification length:   16.8 seconds\n",
      "\n",
      "If we use the mean to extrapolate and include the 0.5 percent of\n",
      "classifications where the reported duration had an error, that means\n",
      "the total time spent is equivalent to 0.57 years of human effort, or\n",
      "2.39 years of FTE (1 person working 40 hours/week, no holiday.)\n",
      "\n",
      "File with ranked list of user classification counts written to western-montana-wildlife-classifications_nclass_byuser_ranked.csv .\n",
      "Saved info for all classifications that have duplicates to western-montana-wildlife-classifications_duplicated_only.csv .\n"
     ]
    }
   ],
   "source": [
    "basic_stats_processing(classification_file, workflow_id=workflow_id, remove_duplicates=True, \n",
    "                       time_elapsed=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note** how the statistics have changed and are only calculated for the non-duplicated classifications from this specific workflow.\n",
    "\n",
    "**Note 2:** when cleaning duplicates, the program saves the *first* classification from the combination of `user_name + subject_id + workflow_id` that's duplicated.\n",
    "\n",
    "## Cleaning up the classifications export\n",
    "\n",
    "Since we're having to clean up the classifications in order to compute the stats, why not print out that file? Most data reduction codes will require classifications that all have the same structure, i.e., which are all from the same `workflow_id` and `workflow_version`. In addition, it's usually best to ignore duplicate classifications. Rather than doing all this work again when we need to reduce (i.e., aggregate) the data later, we may as well print out the cleaned file now. (Alternatively, you can use this as a means of cleaning your classification exports and you get the stats for free!)\n",
    "\n",
    "By default, the program only reads in the columns it needs for the stats, which saves a *lot* of memory when dealing with large files (e.g. millions of classifications). We need to turn off that option in order to produce a file that actually contains the annotations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading classifications from western-montana-wildlife-classifications.csv\n",
      "ERROR: your combination of workflow_id and workflow_version(s) does not exist!\n",
      "Ignoring workflow id/version request and computing stats for ALL classifications instead.\n",
      "File with used subset of classification info written to western-montana-wildlife-classifications-workflow3101-version3.8-nodups.csv .\n"
     ]
    }
   ],
   "source": [
    "# define a new outfile name with some information that will help us later when aggregating the data\n",
    "outfile_cleanclass = project_name + \"-classifications-workflow\" + str(workflow_id) + \"-version3.8-nodups.csv\"\n",
    "\n",
    "# since we've already printed the stats to the screen above, don't re-print them\n",
    "basic_stats_processing(classification_file, workflow_id=workflow_id, workflow_version=3.8, \n",
    "                       remove_duplicates=True, outfile_csv=outfile_cleanclass, \n",
    "                       keep_allcols=True, verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notes on using the basic_classification_processing scripts\n",
    "\n",
    "`basic_classification_processing.py` is written so that you can do a few things independently of computing *all* the stats, but also you can use the `basic_stats_processing()` function to do everything you need. You can also run it from the command line: try \n",
    "\n",
    " `%> python basic_classification_processing.py` \n",
    "\n",
    "to see the syntax in that case. You can run this script each time you are about to aggregate your data on the latest classification export to produce a clean export with no duplicates (and only live classifications, if you wish) or to split a full project export into multiple based on workflows, or to extract only a specific workflow version from a workflow-specific extract. And, with each of these, if you keep `verbose` on, you'll get the stats for free."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
